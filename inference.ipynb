{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKAUiLXklJiAtlsXsYCv5h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SandroMuradashvili/CNN/blob/main/inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cwbPnWwxA2so",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7e3fc88-89c8-4aee-ee17-3ca30c1d879b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Libraries imported\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# NOTEBOOK 2: inference.ipynb\n",
        "# Simpsons Character Classification - Inference Pipeline\n",
        "# ============================================================================\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: Import Required Libraries\n",
        "# ============================================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import json\n",
        "\n",
        "print(\"✓ Libraries imported\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# STEP 2: Define CNN Architecture (Same as training)\n",
        "# ============================================================================\n",
        "class SimpleCNN(nn.Module):\n",
        "    \"\"\"Custom CNN for Simpsons Character Classification\"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=41):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        # Convolutional Block 1\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        # Convolutional Block 2\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        # Convolutional Block 3\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        # Convolutional Block 4\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256 * 8 * 8, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "print(\"✓ CNN architecture defined\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbjRZDKgcVIA",
        "outputId": "cd8db924-58cb-4fd7-fb2b-27aa73217ad8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ CNN architecture defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 3: Define Inference Function\n",
        "# ============================================================================\n",
        "def infer(data_dir, model_path):\n",
        "    \"\"\"\n",
        "    Load trained model and generate predictions for all images in data_dir.\n",
        "\n",
        "    Args:\n",
        "        data_dir (str): Path to directory containing test images\n",
        "        model_path (str): Path to saved model file (.pth)\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary mapping filename to predicted class name\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"INFERENCE PIPELINE\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Data directory: {data_dir}\")\n",
        "    print(f\"Model path: {model_path}\")\n",
        "\n",
        "    # Check if paths exist\n",
        "    if not os.path.exists(data_dir):\n",
        "        raise FileNotFoundError(f\"Data directory not found: {data_dir}\")\n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
        "\n",
        "    # Set device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Load model checkpoint\n",
        "    print(\"\\nLoading model...\")\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "\n",
        "    # Extract model info\n",
        "    if 'class_names' in checkpoint:\n",
        "        class_names = checkpoint['class_names']\n",
        "        num_classes = len(class_names)\n",
        "    elif 'num_classes' in checkpoint:\n",
        "        num_classes = checkpoint['num_classes']\n",
        "        # If class_names not saved, create generic ones\n",
        "        class_names = [f\"class_{i}\" for i in range(num_classes)]\n",
        "    else:\n",
        "        raise ValueError(\"Model checkpoint doesn't contain class information!\")\n",
        "\n",
        "    print(f\"✓ Model loaded with {num_classes} classes\")\n",
        "\n",
        "    # Initialize model\n",
        "    model = SimpleCNN(num_classes=num_classes)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    print(\"✓ Model ready for inference\")\n",
        "\n",
        "    # Define image transforms (same as validation)\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Get all image files from data_dir\n",
        "    print(f\"\\nScanning directory: {data_dir}\")\n",
        "    image_files = []\n",
        "\n",
        "    # Check if data_dir contains images directly or in subdirectories\n",
        "    for root, dirs, files in os.walk(data_dir):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.jpg', '.jpeg', '.png')) and not file.startswith('.'):\n",
        "                image_files.append(os.path.join(root, file))\n",
        "\n",
        "    if len(image_files) == 0:\n",
        "        raise ValueError(f\"No images found in {data_dir}\")\n",
        "\n",
        "    print(f\"✓ Found {len(image_files)} images to process\")\n",
        "\n",
        "    # Run inference on all images\n",
        "    results = {}\n",
        "    print(\"\\nRunning inference...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, img_path in enumerate(image_files):\n",
        "            # Load and preprocess image\n",
        "            try:\n",
        "                image = Image.open(img_path).convert('RGB')\n",
        "                image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "                # Get prediction\n",
        "                output = model(image_tensor)\n",
        "                _, predicted = output.max(1)\n",
        "                predicted_class = class_names[predicted.item()]\n",
        "\n",
        "                # Store result with just filename (not full path)\n",
        "                filename = os.path.basename(img_path)\n",
        "                results[filename] = predicted_class\n",
        "\n",
        "                # Print progress every 100 images\n",
        "                if (idx + 1) % 100 == 0:\n",
        "                    print(f\"  Processed {idx + 1}/{len(image_files)} images...\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  Warning: Failed to process {img_path}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "    print(f\"✓ Inference complete! Processed {len(results)} images\")\n",
        "\n",
        "    # Save results to JSON\n",
        "    output_file = 'results.json'\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "    print(f\"✓ Results saved to: {output_file}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    return results\n",
        "\n",
        "print(\"✓ Inference function defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjdLzVLncVt7",
        "outputId": "14a61ffe-bb18-4ffb-ccb7-bf5b74f10b3b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Inference function defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 4: Run Inference (Example Usage)\n",
        "# ============================================================================\n",
        "# Example: Run inference on test data\n",
        "# Modify these paths according to your setup\n",
        "\n",
        "# Path to test data directory (will be provided by professor)\n",
        "TEST_DATA_DIR = './test_data'  # Change this to actual test directory\n",
        "\n",
        "# Path to trained model\n",
        "MODEL_PATH = 'simpson_model.pth'  # Or 'simpson_model_best.pth'\n",
        "\n",
        "# Check if test data exists (for demonstration)\n",
        "if os.path.exists(TEST_DATA_DIR):\n",
        "    print(\"Running inference on test data...\")\n",
        "    results = infer(TEST_DATA_DIR, MODEL_PATH)\n",
        "\n",
        "    # Display first few predictions\n",
        "    print(\"\\nSample predictions:\")\n",
        "    for i, (filename, pred_class) in enumerate(list(results.items())[:5]):\n",
        "        print(f\"  {filename} → {pred_class}\")\n",
        "\n",
        "    print(f\"\\nTotal predictions: {len(results)}\")\n",
        "    print(\"Results saved to 'results.json'\")\n",
        "else:\n",
        "    print(f\"\\n⚠️  Test data directory not found: {TEST_DATA_DIR}\")\n",
        "    print(\"This is normal if you haven't created test data yet.\")\n",
        "    print(\"\\nTo use this notebook:\")\n",
        "    print(\"1. Set TEST_DATA_DIR to your test images directory\")\n",
        "    print(\"2. Make sure MODEL_PATH points to your trained model\")\n",
        "    print(\"3. Run all cells\")\n",
        "    print(\"\\nThe infer() function is ready to use!\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 5: Verification\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"INFERENCE NOTEBOOK READY!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nThis notebook provides:\")\n",
        "print(\"  ✓ infer(data_dir, model_path) function\")\n",
        "print(\"  ✓ Automatic results.json generation\")\n",
        "print(\"  ✓ Support for GPU acceleration\")\n",
        "print(\"  ✓ Progress tracking during inference\")\n",
        "print(\"\\nTo use:\")\n",
        "print(\"  1. Update TEST_DATA_DIR to point to your test images\")\n",
        "print(\"  2. Update MODEL_PATH if needed\")\n",
        "print(\"  3. Run all cells\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "loQRWwVycVxO",
        "outputId": "95124245-e74b-4b62-908c-0b3f419bc5d0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⚠️  Test data directory not found: ./test_data\n",
            "This is normal if you haven't created test data yet.\n",
            "\n",
            "To use this notebook:\n",
            "1. Set TEST_DATA_DIR to your test images directory\n",
            "2. Make sure MODEL_PATH points to your trained model\n",
            "3. Run all cells\n",
            "\n",
            "The infer() function is ready to use!\n",
            "\n",
            "======================================================================\n",
            "INFERENCE NOTEBOOK READY!\n",
            "======================================================================\n",
            "\n",
            "This notebook provides:\n",
            "  ✓ infer(data_dir, model_path) function\n",
            "  ✓ Automatic results.json generation\n",
            "  ✓ Support for GPU acceleration\n",
            "  ✓ Progress tracking during inference\n",
            "\n",
            "To use:\n",
            "  1. Update TEST_DATA_DIR to point to your test images\n",
            "  2. Update MODEL_PATH if needed\n",
            "  3. Run all cells\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ]
}